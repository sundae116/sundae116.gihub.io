---
layout: post
title:  Standford Andrew Ng，吴恩达老师机器学习公开课与笔记(Material)！
date:   2018-10-27 22:07:20 +0300
description: # Add post description (optional)
img: post-8.jpg # Add image post (optional)
tags: [Blog, Mind,Machine Learning]
author: 姜小白 # Add name author (optional)
---

最近在听斯坦福大学CS229公开课，主要是最近的研究方向比较关注在机器学习领域，作为入门课程的话，吴恩达老师的课还是很受欢迎的。刚开始看也觉得老师讲课很认真，很多细节都有在板书。但是看着看着我就发现了，吴老师的课其实和我之前上的课程，即使讲了同样的知识点，但是他们也是截然不同的。

就举个很简单的例子，当吴老师讲解线性归回模型假设的随机扰动项设定的时候，老师讲解了这个扰动的设定，是考虑到要将那些目前没有包含在我们假设的这个模型中的因素，包裹进来，因为不能一一假设所有的影响因素，毕竟有些影响因素的作用是微乎其微的，但又不能忽视它们作为一个整体存在，所以就用一个扰动项epsilon代替。——其实这是统计建模中一个简单到不能再简单的设定，但是当初就因为我一直搞不懂为什么会存在这样一个扰动项，而非常苦恼。当然那个时候我接受的教育是模型里都带着这么一个......

接着下面就有学生提问，为什么把随机扰动项设定成高斯分布？难道我们不就成了自证自明了吗？——说实在这个问题依然很简单，但同样也困扰了我很久，这个问题我忘记是哪位老师教的，当时对方只是说你记住，这就是个假设。但是吴老师在课程中给的答案就明显诚恳很多，他坦言这样设定的原因有两个：1是我们需要有一个便于数学推导的假定，而这个高斯假设让我们为我们数学推算提供了便利(承认这个假设不完美)2.根据中心极限定理的一些证明，这至少可以作为一个描绘大多数情况的备选项，当然不一定符合大多数的情况下的数据，就应该有其他的假设。(说明这个假设可以改进)

别看这个问题很小，这就是学习和做研究的区别，如果你就认为这个假设不是一个函待改进的bug，而是一个非常合理的前提，那么我们在做的事情，可能真的就是“自证自明”的一场愚蠢的数字游戏。知道了这个假设可以放宽，所以才有了后面关于卡方分布，F分布等等各种假定的出现，帮助我们拟合更符合经济学意义的模型。

说到这里还是觉得只读书不思考，就会产生很多问题，人云亦云是一个，没有质疑通篇接受也是很危险的，危险的不只是不抱着怀疑的态度去学习的学生，更危险的是用教条和本本主义去传播本来很有益的知识，却不支持学生去问问题的有害的教学模式。说实话我因为在读博阶段的填鸭式教育，一度处于迷惘崩溃的边缘，我一方面觉得那些言论都是在扯淡，另一方面还要学着那些东西去说话，怪模怪样，写出的文字一个正常的人都读不懂......索性直接懈怠了——你们说什么我就信什么吧！直到我开始看更前沿的资料，学更系统的教材，而不是那些翻译过来的二手知识，才觉得头脑清晰了很多。如果说有种照本宣科教育是有害的，我应该会诚实的说，之前的我，是一名受害者。

看了吴老师的课程给我的启发显然不只是这些，目前每天都在学习课程，地址放在下面，机器学习入门阶段的朋友或者对统计学感兴趣的可以作为参考：

吴恩达machine learning课程
=========================
讲师：Andrew Ng    
------------
吴恩达（1976-，英文名：Andrew Ng），华裔美国人，是斯坦福大学计算机科学系和电子工程系副教授，人工智能实验室主任。吴恩达是人工智能和机器学习领域国际上最权威的学者之一。吴恩达也是在线教育平台Coursera的联合创始人（with Daphne Koller）。2014年5月16日，吴恩达加入百度，担任百度公司首席科学家，负责百度研究院的领导工作，尤其是Baidu Brain计划。
中文名    吴恩达 
外文名    Andrew Y. Ng 
国    籍    美国 
出生地    英国伦敦 
出生日期    1976年 
职    业    计算机科学家 
毕业院校    University of California, Berkeley 
主要成就    人工智能和机器学习领域国际最权威学者之一 
博士导师    Michael I. Jordan  

课程对应的笔记内容链接
=====================
https://nbviewer.jupyter.org/github/sundae116/My-Machine-Learning/blob/master/Stanford-CS-229-CN/CS229Notes-CN/ReadMe.ipynb

如果要收藏下载的话，就可以通过百度云链接
=====================================  

[斯坦福大学公开课 ：机器学习课程01_机器学习的动机与应用_中英双字幕.mp4](http://pan.baidu.com/s/1c1jGNg0)  
[斯坦福大学公开课 ：机器学习课程02_监督学习应用梯度下降_中英双字幕.mp4](http://pan.baidu.com/s/1c0RzUj2)  
[斯坦福大学公开课 ：机器学习课程03_欠拟合与过拟合的概念_中英双字幕.mp4](http://pan.baidu.com/s/1gdRZKvp)  
[斯坦福大学公开课 ：机器学习课程04_牛顿方法_中英双字幕.mp4](http://pan.baidu.com/s/1kTTn5bx)  
[斯坦福大学公开课 ：机器学习课程05_生成学习算法_中英双字幕.mp4](http://pan.baidu.com/s/1jHj48RW)  
[斯坦福大学公开课 ：机器学习课程06_朴素贝叶斯算法_中英双字幕.mp4](http://pan.baidu.com/s/1bnX78YF)  
[斯坦福大学公开课 ：机器学习课程07_最优间隔分类器问题_中英双字幕.mp4](http://pan.baidu.com/s/1jGRnFOM)  
[斯坦福大学公开课 ：机器学习课程08_顺序最小优化算法_中英双字幕.mp4](http://pan.baidu.com/s/1gdWJ2Hd)  
[斯坦福大学公开课 ：机器学习课程09_经验风险最小化_中英双字幕.mp4](http://pan.baidu.com/s/1ntTPyNf)  
[斯坦福大学公开课 ：机器学习课程10_特征选择_中英双字幕.mp4](http://pan.baidu.com/s/1dEy7RsH)  
[斯坦福大学公开课 ：机器学习课程11_贝叶斯统计正则化_中英双字幕.mp4](http://pan.baidu.com/s/1geioLOJ)  
[斯坦福大学公开课 ：机器学习课程12_K-means算法_中英双字幕.mp4](http://pan.baidu.com/s/1i3Vt329)  
[斯坦福大学公开课 ：机器学习课程13_高斯混合模型_中英双字幕.mp4](http://pan.baidu.com/s/1YV6uM)  
[斯坦福大学公开课 ：机器学习课程14_主成分分析法_中英双字幕.mp4](http://pan.baidu.com/s/1skg82Ah)  
[斯坦福大学公开课 ：机器学习课程15_奇异值分解_中英双字幕.mp4](http://pan.baidu.com/s/1kUiM9oV)  
[斯坦福大学公开课 ：机器学习课程16_马尔可夫决策过程_中英双字幕.mp4](http://pan.baidu.com/s/1nu0Zy57)  
[斯坦福大学公开课 ：机器学习课程17_离散与维数灾难_中英双字幕.mp4](http://pan.baidu.com/s/1eRiWKpW)  
[斯坦福大学公开课 ：机器学习课程18_线性二次型调节控制_中英双字幕.mp4](http://pan.baidu.com/s/1bnODbw)  
[斯坦福大学公开课 ：机器学习课程19_微分动态规划_中英双字幕.mp4](http://pan.baidu.com/s/1bvqkzG)  
[斯坦福大学公开课 ：机器学习课程20_策略搜索_中英双字幕.mp4](http://pan.baidu.com/s/1mhkMziC)  


同学们如果在线看，推荐网易公开课的收看链接  
--------------
http://open.163.com/special/opencourse/machinelearning.html
----------------------------

